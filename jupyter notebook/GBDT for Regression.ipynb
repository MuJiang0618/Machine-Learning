{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBDT for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2018/06/15\n",
    "from numpy import *\n",
    "import urllib.request\n",
    "\n",
    "def loadOnlineDataSet(url):\n",
    "    raw_data = urllib.request.urlopen(url)\n",
    "    dataSet = loadtxt(raw_data, delimiter=\" \")\n",
    "    return dataSet\n",
    "\n",
    "def loadLocalData(route):\n",
    "    fr = open(route)\n",
    "    vector = []\n",
    "    for line in fr.readlines():\n",
    "        temp_list = line.strip().split()\n",
    "        vector.append(list(map(float, temp_list)))\n",
    "\n",
    "    return array(vector)\n",
    "\n",
    "def makeDataSet():\n",
    "    X, Y = make_regression(500, 7, 7)\n",
    "    X_normalized = preprocessing.normalize(X, norm='l2') #'l1'(绝对值之和)、'l2'范式(几何距离)\n",
    "    return c_[X_normalized, Y]\n",
    "\n",
    "def binSplit(dataSet, feat, val):\n",
    "    subSetL = dataSet[nonzero(dataSet[:, feat] <= val)[0], :]\n",
    "    subSetR = dataSet[nonzero(dataSet[:, feat] > val)[0], :]\n",
    "\n",
    "    return subSetL, subSetR\n",
    "\n",
    "def leaf_cls(Leaf_dataSet):\n",
    "    y = Leaf_dataSet[:, -1]\n",
    "    labels = {}\n",
    "    for i in range(len(y)):\n",
    "        if y[i] not in labels.keys():\n",
    "            labels[y[i]] = 0\n",
    "        labels[y[i]] += 1\n",
    "\n",
    "    max_label = 1 ; major_label = 0\n",
    "    for label in labels.keys():\n",
    "        if labels[label] > max_label:\n",
    "            max_label = labels[label]\n",
    "            major_label = label\n",
    "\n",
    "    return major_label\n",
    "\n",
    "def leaf_reg(Leaf_dataSet):\n",
    "    return mean(Leaf_dataSet[:, -1])\n",
    "\n",
    "def err_reg(dataSet):\n",
    "    n = len(dataSet)\n",
    "    return n * var(dataSet)\n",
    "\n",
    "def err_cls(sub_y):\n",
    "    labels = {}\n",
    "    for i in range(len(sub_y)):\n",
    "        if sub_y[i] not in labels.keys():\n",
    "            labels[sub_y[i]] = 0\n",
    "        labels[sub_y[i]] += 1\n",
    "    gini = 1\n",
    "    for j in labels.keys():\n",
    "        prob = labels[j] / len(sub_y)\n",
    "        gini -= prob**2\n",
    "\n",
    "    return gini\n",
    "\n",
    "def chooseBestSplit(dataSet, prune_tol=(0, 4), leafNode=leaf_reg, err_cal=err_reg):\n",
    "    lowest_error = err_cal(dataSet[:, -1]) ; best_splitFeat = -1 ; best_splitVal = 0.0\n",
    "    \n",
    "    for feat in range( len(dataSet[0]) - 1):\n",
    "        points = list(set(dataSet[:, feat]))\n",
    "        bi_point = []\n",
    "        for i in range(len(points) - 1):\n",
    "            bi_point.append( (points[i] + points[i+1]) / 2)\n",
    "        for val in bi_point:\n",
    "            subSetL, subSetR = binSplit(dataSet, feat, val)\n",
    "            err = err_cal(subSetL[:, -1]) + err_cal(subSetR[:, -1])\n",
    "            \n",
    "            if err < lowest_error:\n",
    "                lowest_error = err\n",
    "                best_splitVal = val\n",
    "                best_splitFeat = feat\n",
    "\n",
    "    org_err = err_cal(dataSet[:, -1])\n",
    "    tol_err = prune_tol[0] ; tol_num = prune_tol[1]\n",
    "    if (org_err - lowest_error) < tol_err:\n",
    "        return None, leafNode(dataSet)\n",
    "\n",
    "    subSetL, subSetR = binSplit(dataSet, best_splitFeat, best_splitVal)\n",
    "    if len(subSetL) + len(subSetR) < tol_num:\n",
    "        return None, leafNode(dataSet)\n",
    "\n",
    "    return best_splitFeat, best_splitVal\n",
    "\n",
    "def g_predict(tree, test_data):\n",
    "    if not type(tree) == dict:\n",
    "        return tree\n",
    "\n",
    "    else:\n",
    "        feat_index = tree['feat'] ; split_val = tree['val']\n",
    "        if test_data[feat_index] < split_val:\n",
    "            return g_predict(tree['left'], test_data)\n",
    "        else:\n",
    "            return g_predict(tree['right'], test_data)\n",
    "\n",
    "def get_residuals(trees, org_dataSet):\n",
    "    scores = []\n",
    "    for i in org_dataSet[:, :-1]:\n",
    "        score = 0.0 \n",
    "        for tree in trees:\n",
    "            score += g_predict(tree, i)\n",
    "        scores.append(score)\n",
    "    residuals = org_dataSet[:, -1] - scores\n",
    "\n",
    "    return residuals\n",
    "\n",
    "def creat_Tree(dataSet, leafNode, err_cal, max_depth = 8):    #拟合残差\n",
    "    if max_depth == 0:\n",
    "        return leafNode(dataSet)\n",
    "\n",
    "    best_splitFeat, best_splitVal = chooseBestSplit(dataSet)\n",
    "    if best_splitFeat == None:\n",
    "        return best_splitVal\n",
    "\n",
    "    tree_dict = {}\n",
    "    subSetL, subSetR = binSplit(dataSet, best_splitFeat, best_splitVal)\n",
    "    tree_dict['feat'] = best_splitFeat ; tree_dict['val'] = best_splitVal\n",
    "    tree_dict['left'] = creat_Tree(subSetL, leafNode, err_cal, max_depth-1)\n",
    "    tree_dict['right'] = creat_Tree(subSetR, leafNode, err_cal, max_depth-1)\n",
    "\n",
    "    return tree_dict\n",
    "\n",
    "def creat_GBDT(dataSet, n_tree):\n",
    "    tree_dict =[]\n",
    "    org_dataSet = dataSet.copy()\n",
    "    first_tree = creat_Tree(dataSet, leaf_reg, err_reg)\n",
    "    tree_dict.append(first_tree)\n",
    "    \n",
    "    for i in range(n_tree - 1):\n",
    "        residuals = get_residuals(tree_dict, org_dataSet)\n",
    "        dataSet[:, -1] = residuals     #构建树的时候用residual_dataSet，因为要拟合的是残差，\n",
    "        #得到残差的时候只需要各样本的属性来计算分数，所以用原始数据集\n",
    "        new_tree = creat_Tree(dataSet, leaf_reg, err_reg)\n",
    "        tree_dict.append(new_tree)\n",
    "\n",
    "    return tree_dict\n",
    "\n",
    "def test():\n",
    "    dataSet = loadLocalData(r'C:\\Users\\Administrator\\Desktop\\ML dataSet\\regression.txt')[:, 1:]\n",
    "    dataSet_copy = dataSet.copy()\n",
    "    trees = creat_GBDT(dataSet[:180], 2)\n",
    "    print(trees)\n",
    "    error = get_residuals(trees, dataSet_copy[180:])\n",
    "    sqare_error = (error **2).sum()\n",
    "    print('The sqare error is %s' %sqare_error)\n",
    "    \n",
    "    return 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
