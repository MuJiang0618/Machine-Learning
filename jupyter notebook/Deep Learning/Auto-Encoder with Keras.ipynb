{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-Encoder with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\study\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255. - 0.5   #把像素值限制到-0.5 to 0.5\n",
    "x_test = x_test.astype('float32') / 255. - 0.5\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], -1))  # 将28X28的像素矩阵转化为行向量\n",
    "x_test = x_test.reshape((x_test.shape[0], -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPreProcess(x_train):\n",
    "    x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "    \n",
    "    return x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder section\n",
    "def autoEncoder_train(x_train, encoded_dim=8):\n",
    "#     x_train = dataPreProcess(x_train)\n",
    "\n",
    "    input_img = Input(shape=(x_train.shape[1], ))   # 实例化1个tensor\n",
    "    encoded_model = Dense(128, activation='relu')(input_img)\n",
    "    encoded_model = Dense(64, activation='relu')(encoded_model)\n",
    "    encoded_model = Dense(10, activation='relu')(encoded_model)\n",
    "    code_layer = Dense(encoded_dim)(encoded_model)\n",
    "    \n",
    "    decoded_model = Dense(10, activation='relu')(code_layer)\n",
    "    decoded_model = Dense(64, activation='relu')(decoded_model)\n",
    "    decoded_model = Dense(128, activation='relu')(decoded_model)\n",
    "    decoded_model = Dense(784, activation='relu')(decoded_model)\n",
    "    \n",
    "    output_decoded_picture = Model(input_img, decoded_model)\n",
    "    output_decoded_picture.compile(loss='mse', optimizer='Adam')\n",
    "    output_decoded_picture.fit(x_train, x_train, epochs=1)\n",
    "    \n",
    "    output_code = Model(input_img, code_layer)\n",
    "    \n",
    "    return output_code, output_decoded_picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.2289\n"
     ]
    }
   ],
   "source": [
    "output_code_layer, output_decoded_picture_layer = autoEncoder_train(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoEncoder(picture):\n",
    "    plt.ion()\n",
    "    print('original picture↓')\n",
    "    plt.imshow(picture.reshape(28, 28), cmap='Greys')\n",
    "    plt.show()\n",
    "#     output_code_layer, output_decoded_picture_layer = autoEncoder_train(x_train, encoded_dim)\n",
    "    code = output_code_layer.predict(picture.reshape(-1, 784))\n",
    "    decoded_picture = output_decoded_picture_layer.predict(picture.reshape(-1, 784))\n",
    "    \n",
    "    print('decoded picture↓')\n",
    "    plt.imshow(decoded_picture[0].reshape(28, 28), cmap='Greys')\n",
    "    plt.show()\n",
    "    \n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original picture↓\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded picture↓\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "code = autoEncoder(x_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "answer: 注意Model对象的predict, fit方法都要求输入的对象是ndarray, 不能是(784, )之类的1阶ndarray, 如果要输入单个样本, 用 sample.reshape(-1, 任意数字), 这样就转化成了2阶ndarray. 在scikit-learn中, estimator的predict, fit方法也有这样的要求, 值得注意"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也许上述要求是因为Input(shape(123, ))的原因?也许这样就能处理一次输入多个样本并给出estimation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
