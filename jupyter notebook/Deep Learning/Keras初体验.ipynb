{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras用起来真是舒服"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = make_classification(n_classes=2, n_features=4, n_clusters_per_class=1, n_samples=200, n_redundant=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/68\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.7458 - acc: 0.4700\n",
      "Epoch 2/68\n",
      "200/200 [==============================] - 0s 584us/step - loss: 0.7195 - acc: 0.4350\n",
      "Epoch 3/68\n",
      "200/200 [==============================] - 0s 631us/step - loss: 0.6997 - acc: 0.4350\n",
      "Epoch 4/68\n",
      "200/200 [==============================] - 0s 608us/step - loss: 0.6853 - acc: 0.5100\n",
      "Epoch 5/68\n",
      "200/200 [==============================] - 0s 512us/step - loss: 0.6722 - acc: 0.5800\n",
      "Epoch 6/68\n",
      "200/200 [==============================] - 0s 392us/step - loss: 0.6608 - acc: 0.6650\n",
      "Epoch 7/68\n",
      "200/200 [==============================] - 0s 360us/step - loss: 0.6490 - acc: 0.7050\n",
      "Epoch 8/68\n",
      "200/200 [==============================] - 0s 354us/step - loss: 0.6348 - acc: 0.7400\n",
      "Epoch 9/68\n",
      "200/200 [==============================] - 0s 334us/step - loss: 0.6191 - acc: 0.7950\n",
      "Epoch 10/68\n",
      "200/200 [==============================] - 0s 364us/step - loss: 0.6004 - acc: 0.7950\n",
      "Epoch 11/68\n",
      "200/200 [==============================] - 0s 364us/step - loss: 0.5797 - acc: 0.8250\n",
      "Epoch 12/68\n",
      "200/200 [==============================] - 0s 339us/step - loss: 0.5576 - acc: 0.8500\n",
      "Epoch 13/68\n",
      "200/200 [==============================] - 0s 317us/step - loss: 0.5327 - acc: 0.8700\n",
      "Epoch 14/68\n",
      "200/200 [==============================] - 0s 319us/step - loss: 0.5085 - acc: 0.8800\n",
      "Epoch 15/68\n",
      "200/200 [==============================] - 0s 311us/step - loss: 0.4844 - acc: 0.8850\n",
      "Epoch 16/68\n",
      "200/200 [==============================] - 0s 299us/step - loss: 0.4641 - acc: 0.9000\n",
      "Epoch 17/68\n",
      "200/200 [==============================] - 0s 294us/step - loss: 0.4444 - acc: 0.9200\n",
      "Epoch 18/68\n",
      "200/200 [==============================] - 0s 314us/step - loss: 0.4292 - acc: 0.9250\n",
      "Epoch 19/68\n",
      "200/200 [==============================] - 0s 295us/step - loss: 0.4098 - acc: 0.9400\n",
      "Epoch 20/68\n",
      "200/200 [==============================] - 0s 319us/step - loss: 0.3369 - acc: 0.9450\n",
      "Epoch 21/68\n",
      "200/200 [==============================] - 0s 334us/step - loss: 0.2602 - acc: 0.9550\n",
      "Epoch 22/68\n",
      "200/200 [==============================] - 0s 274us/step - loss: 0.2037 - acc: 0.9550\n",
      "Epoch 23/68\n",
      "200/200 [==============================] - 0s 239us/step - loss: 0.1655 - acc: 0.9600\n",
      "Epoch 24/68\n",
      "200/200 [==============================] - 0s 223us/step - loss: 0.1397 - acc: 0.9700\n",
      "Epoch 25/68\n",
      "200/200 [==============================] - 0s 245us/step - loss: 0.1206 - acc: 0.9700\n",
      "Epoch 26/68\n",
      "200/200 [==============================] - 0s 234us/step - loss: 0.1106 - acc: 0.9750\n",
      "Epoch 27/68\n",
      "200/200 [==============================] - 0s 238us/step - loss: 0.1011 - acc: 0.9750\n",
      "Epoch 28/68\n",
      "200/200 [==============================] - 0s 230us/step - loss: 0.0946 - acc: 0.9750\n",
      "Epoch 29/68\n",
      "200/200 [==============================] - 0s 247us/step - loss: 0.0895 - acc: 0.9750\n",
      "Epoch 30/68\n",
      "200/200 [==============================] - 0s 234us/step - loss: 0.0863 - acc: 0.9750\n",
      "Epoch 31/68\n",
      "200/200 [==============================] - 0s 254us/step - loss: 0.0834 - acc: 0.9750\n",
      "Epoch 32/68\n",
      "200/200 [==============================] - 0s 254us/step - loss: 0.0797 - acc: 0.9750\n",
      "Epoch 33/68\n",
      "200/200 [==============================] - 0s 244us/step - loss: 0.0773 - acc: 0.9750\n",
      "Epoch 34/68\n",
      "200/200 [==============================] - 0s 242us/step - loss: 0.0756 - acc: 0.9750\n",
      "Epoch 35/68\n",
      "200/200 [==============================] - 0s 254us/step - loss: 0.0747 - acc: 0.9750\n",
      "Epoch 36/68\n",
      "200/200 [==============================] - 0s 239us/step - loss: 0.0701 - acc: 0.9750\n",
      "Epoch 37/68\n",
      "200/200 [==============================] - 0s 201us/step - loss: 0.0705 - acc: 0.9750\n",
      "Epoch 38/68\n",
      "200/200 [==============================] - 0s 208us/step - loss: 0.0690 - acc: 0.9800\n",
      "Epoch 39/68\n",
      "200/200 [==============================] - 0s 244us/step - loss: 0.0671 - acc: 0.9750\n",
      "Epoch 40/68\n",
      "200/200 [==============================] - 0s 251us/step - loss: 0.0675 - acc: 0.9800\n",
      "Epoch 41/68\n",
      "200/200 [==============================] - 0s 245us/step - loss: 0.0658 - acc: 0.9800\n",
      "Epoch 42/68\n",
      "200/200 [==============================] - 0s 263us/step - loss: 0.0655 - acc: 0.9750\n",
      "Epoch 43/68\n",
      "200/200 [==============================] - 0s 255us/step - loss: 0.0633 - acc: 0.9800\n",
      "Epoch 44/68\n",
      "200/200 [==============================] - 0s 239us/step - loss: 0.0626 - acc: 0.9800\n",
      "Epoch 45/68\n",
      "200/200 [==============================] - 0s 244us/step - loss: 0.0614 - acc: 0.9800\n",
      "Epoch 46/68\n",
      "200/200 [==============================] - 0s 259us/step - loss: 0.0611 - acc: 0.9850\n",
      "Epoch 47/68\n",
      "200/200 [==============================] - 0s 254us/step - loss: 0.0607 - acc: 0.9800\n",
      "Epoch 48/68\n",
      "200/200 [==============================] - 0s 234us/step - loss: 0.0607 - acc: 0.9850\n",
      "Epoch 49/68\n",
      "200/200 [==============================] - 0s 194us/step - loss: 0.0593 - acc: 0.9850\n",
      "Epoch 50/68\n",
      "200/200 [==============================] - 0s 196us/step - loss: 0.0590 - acc: 0.9850\n",
      "Epoch 51/68\n",
      "200/200 [==============================] - 0s 204us/step - loss: 0.0585 - acc: 0.9850\n",
      "Epoch 52/68\n",
      "200/200 [==============================] - 0s 205us/step - loss: 0.0572 - acc: 0.9850\n",
      "Epoch 53/68\n",
      "200/200 [==============================] - 0s 195us/step - loss: 0.0579 - acc: 0.9850\n",
      "Epoch 54/68\n",
      "200/200 [==============================] - 0s 204us/step - loss: 0.0585 - acc: 0.9850\n",
      "Epoch 55/68\n",
      "200/200 [==============================] - 0s 207us/step - loss: 0.0568 - acc: 0.9850\n",
      "Epoch 56/68\n",
      "200/200 [==============================] - 0s 199us/step - loss: 0.0562 - acc: 0.9850\n",
      "Epoch 57/68\n",
      "200/200 [==============================] - 0s 193us/step - loss: 0.0555 - acc: 0.9850\n",
      "Epoch 58/68\n",
      "200/200 [==============================] - 0s 194us/step - loss: 0.0558 - acc: 0.9850\n",
      "Epoch 59/68\n",
      "200/200 [==============================] - 0s 145us/step - loss: 0.0561 - acc: 0.9850\n",
      "Epoch 60/68\n",
      "200/200 [==============================] - 0s 225us/step - loss: 0.0545 - acc: 0.9850\n",
      "Epoch 61/68\n",
      "200/200 [==============================] - 0s 239us/step - loss: 0.0549 - acc: 0.9850\n",
      "Epoch 62/68\n",
      "200/200 [==============================] - 0s 242us/step - loss: 0.0547 - acc: 0.9850\n",
      "Epoch 63/68\n",
      "200/200 [==============================] - 0s 240us/step - loss: 0.0535 - acc: 0.9850\n",
      "Epoch 64/68\n",
      "200/200 [==============================] - 0s 235us/step - loss: 0.0548 - acc: 0.9850\n",
      "Epoch 65/68\n",
      "200/200 [==============================] - 0s 153us/step - loss: 0.0538 - acc: 0.9850\n",
      "Epoch 66/68\n",
      "200/200 [==============================] - 0s 150us/step - loss: 0.0537 - acc: 0.9850\n",
      "Epoch 67/68\n",
      "200/200 [==============================] - 0s 138us/step - loss: 0.0532 - acc: 0.9850\n",
      "Epoch 68/68\n",
      "200/200 [==============================] - 0s 140us/step - loss: 0.0537 - acc: 0.9850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ccaae4a470>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=4, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "# model.fit(dataSet[0][:-20], dataSet[1][:-20], epochs=100)\n",
    "model.fit(dataSet[0], dataSet[1], epochs=68)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
