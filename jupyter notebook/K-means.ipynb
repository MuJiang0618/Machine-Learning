{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "\n",
    "def loadDataSet(fileName=r'C:\\Users\\Administrator\\Desktop\\testSet.txt'): \n",
    "    dataMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        curLine = line.strip().split()\n",
    "        fltLine = list(map(float, curLine) ) #python3中map返回迭代器,所以这里要list()\n",
    "        dataMat.append(fltLine)\n",
    "    fr.close()\n",
    "    return dataMat\n",
    "\n",
    "def distEclud(vecA, vecB):\n",
    "    return sqrt(sum(power(vecA - vecB, 2)))\n",
    "\n",
    "# 为给定数据集构建一个包含 k 个随机质心的集合。随机质心必须要在整个数据集的边界之内，这可以通过找到数据集每一维的最小和最大值来完成。然后生成 0~1.0 之间的随机数并通过取值范围和最小值，以便确保随机点在数据的边界之内。\n",
    "def randCent(dataSet, k):\n",
    "    n = dataSet.shape[1] # 列的数量\n",
    "    centroids = mat(zeros((k,n)) ) # 创建k个质心矩阵\n",
    "    for j in range(n): # 创建随机簇质心，并且在每一维的边界内\n",
    "        minJ = min(dataSet[:,j])    # 最小值\n",
    "        rangeJ = float(max(dataSet[:, j]) - minJ)    # 范围 = 最大值 - 最小值\n",
    "        centroids[:,j] = mat(minJ + rangeJ * random.rand(k,1))    # 为k个质心赋予在数据集范围内的随机值\n",
    "    return centroids\n",
    "\n",
    "def kMeans(dataSet, k, dist_count=distEclud, create_Cent=randCent):\n",
    "    m, n = dataSet.shape\n",
    "    cent_Mat = create_Cent(dataSet, k)   #创建质心簇矩阵\n",
    "    clusterAssment = zeros((m, 2))  #保存每个数据点的簇分配结果和平方误差\n",
    "    change_flag = True\n",
    "    while change_flag:\n",
    "        change_flag = False\n",
    "        for data_point in range(m):\n",
    "            min_dist = inf ; closest_cent = -1\n",
    "            for cent in range(k):\n",
    "                dist = distEclud(dataSet[data_point, :], cent_Mat[cent, :])\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist ; closest_cent = cent\n",
    "            if clusterAssment[data_point, 0] != closest_cent:   #直到所有数据点所属簇不变为止\n",
    "                change_flag = True\n",
    "            clusterAssment[data_point, :] = closest_cent, dist**2  #平方距离作为误差\n",
    "    #每次遍历后更新质心\n",
    "        for cent in range(k):\n",
    "            owned_point = dataSet[nonzero(clusterAssment[:, 0] == cent)[0] ]\n",
    "            cent_Mat[cent, :] = mean(owned_point, axis= 0)\n",
    "    return cent_Mat, clusterAssment\n",
    "\n",
    "def trial():\n",
    "    dataMat = mat(loadDataSet())\n",
    "    cent_Mat, clusterAssment = kMeans(dataMat, 3)\n",
    "    print(clusterAssment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二分K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二分K-均值聚类算法首先将所有点作为一个簇，然后使用K-均值聚类算法(k=2)对其划分，下一次迭代时选择有最大增益的簇进行划分，重复直到k个簇创建成功"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以克服K均值算法收敛于局部最小值的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2018/03/30\n",
    "# -*- coding:utf-8 -*-\n",
    "from numpy import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def loadDataSet(fileName=r'C:\\Users\\Administrator\\Desktop\\testSet2.txt'): \n",
    "    dataMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        curLine = line.strip().split()\n",
    "        fltLine = list(map(float, curLine) ) #python3中map返回迭代器,所以这里要list()\n",
    "        dataMat.append(fltLine)\n",
    "    fr.close()\n",
    "    return dataMat\n",
    "\n",
    "def distEclud(vecA, vecB):\n",
    "    return sqrt(sum(power(vecA - vecB, 2)))\n",
    "\n",
    "# 为给定数据集构建一个包含 k 个随机质心的集合。随机质心必须要在整个数据集的边界之内，这可以通过找到数据集每一维的最小和最大值来完成。然后生成 0~1.0 之间的随机数并通过取值范围和最小值，以便确保随机点在数据的边界之内。\n",
    "def randCent(dataSet, k):\n",
    "    n = dataSet.shape[1] # 列的数量\n",
    "    centroids = mat(zeros((k,n)) ) # 创建k个质心矩阵\n",
    "    for j in range(n): # 创建随机簇质心，并且在每一维的边界内\n",
    "        minJ = min(dataSet[:,j])    # 最小值\n",
    "        rangeJ = float(max(dataSet[:, j]) - minJ)    # 范围 = 最大值 - 最小值\n",
    "        centroids[:,j] = mat(minJ + rangeJ * random.rand(k,1))    # 为k个质心赋予在数据集范围内的随机值\n",
    "    return centroids\n",
    "\n",
    "def kMeans(dataSet, k, dist_count=distEclud, create_Cent=randCent):\n",
    "    m, n = dataSet.shape\n",
    "    cent_Mat = create_Cent(dataSet, k)   #创建质心簇矩阵\n",
    "    clusterAssment = zeros((m, 2))  #每个数据点与质心的关系,第一列表示所属质心，第二列表示该数据点与所属质心的平方距离\n",
    "    change_flag = True\n",
    "    while change_flag:\n",
    "        change_flag = False\n",
    "        for data_point in range(m):\n",
    "            min_dist = inf ; closest_cent = -1\n",
    "            for cent in range(k):\n",
    "                dist = distEclud(dataSet[data_point, :], cent_Mat[cent, :])\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist ; closest_cent = cent\n",
    "            if clusterAssment[data_point, 0] != closest_cent:   #直到所有数据点所属簇不变为止\n",
    "                change_flag = True\n",
    "            clusterAssment[data_point, :] = closest_cent, dist**2\n",
    "\n",
    "    #每次遍历后更新质心\n",
    "        for cent in range(k):\n",
    "            owned_point = dataSet[nonzero(clusterAssment[:, 0] == cent)[0] ]\n",
    "            cent_Mat[cent, :] = mean(owned_point, axis= 0)\n",
    "\n",
    "    return cent_Mat, clusterAssment\n",
    "\n",
    "def Bi_Kmeans(dataSet, k, dist_cal=distEclud):\n",
    "    m, n = dataSet.shape\n",
    "    clusterAssment = zeros((m, 2))  #一开始所有数据点默认簇都是0\n",
    "    centroid0 = mean(dataSet, axis= 0).tolist()[0]\n",
    "    cent_list = [centroid0]   #为什么要用列表存储簇而不是矩阵，ndarray? 因为列表方便后续的簇划分后添加新簇的质心\n",
    "    for j in range(m):\n",
    "        clusterAssment[j, 1] = dist_cal(dataSet[j, :], mat(centroid0)) **2   #平方距离\n",
    "\n",
    "    while len(cent_list) < k:\n",
    "        lowest_sse = 10e7\n",
    "        for cent in range(len(cent_list)):\n",
    "            pt_in_currentCluster = dataSet[nonzero(clusterAssment[:, 0] == cent)[0], :]   #找到属于当前待划分簇的数据点\n",
    "            split_centMat, split_clusterAssment = kMeans(pt_in_currentCluster, 2)\n",
    "            sse_split = sum(split_clusterAssment[:, 1])\n",
    "            sse_notsplit = sum(clusterAssment[nonzero(clusterAssment[:, 0] != cent)[0], 1])\n",
    "            if (sse_split + sse_notsplit) <  lowest_sse:\n",
    "                best_splitCent = cent\n",
    "                best_centMat = split_centMat\n",
    "                best_clusterAssment = split_clusterAssment.copy()  #质心矩阵没有copy而这个要copy?  因为\n",
    "                lowest_sse = sse_notsplit + sse_split\n",
    "\n",
    "        ##一个簇被划分为2个子簇后,子簇0替代被划分簇的簇号及被划分簇在cent_list中的位置,子簇1簇号为簇列表长度,作为簇列表中最后的簇\n",
    "        best_clusterAssment[nonzero(best_clusterAssment[:, 0] == 0)[0], 0] = best_splitCent      #更新簇号\n",
    "        best_clusterAssment[nonzero(best_clusterAssment[:, 0] == 1)[0], 0] = len(cent_list)\n",
    "        cent_list[best_splitCent] = best_centMat[0].tolist()[0]  \n",
    "        cent_list.append(best_centMat[1].tolist()[0])    #更新簇列表位置\n",
    "        clusterAssment[nonzero(clusterAssment[:, 0] == best_splitCent)[0], :] = best_clusterAssment\n",
    "\n",
    "    return mat(cent_list), clusterAssment\n",
    "\n",
    "def plot_result():\n",
    "    dataSet = mat(loadDataSet())\n",
    "    cent_Mat, clusterAssment = Bi_Kmeans(dataSet, 3)\n",
    "    #先获取质心坐标\n",
    "    cent_x = cent_Mat[:, 0].tolist()\n",
    "    cent_y = cent_Mat[:, 1].tolist()\n",
    "    data_point = []\n",
    "    for i in range(3):\n",
    "        data_point.append(dataSet[nonzero(clusterAssment[:, 0] == i)[0], :].tolist())  #3维list\n",
    "    cent_xlist = [] ; cent_ylist = []\n",
    "    for x in cent_x:\n",
    "        cent_xlist.append(x[0])\n",
    "\n",
    "    for y in cent_y:\n",
    "        cent_ylist.append(y[0])\n",
    "\n",
    "    data_xlist = [] ; data_ylist = []\n",
    "    for cent  in data_point:\n",
    "        temp_xlist = [] ; temp_ylist = []\n",
    "        for q in cent:\n",
    "            temp_xlist.append(q[0])\n",
    "            temp_ylist.append(q[1])\n",
    "        data_xlist.append(temp_xlist)\n",
    "        data_ylist.append(temp_ylist)\n",
    "\n",
    "    plt.scatter(data_xlist[0], data_ylist[0], label='1', color='g', s=25, marker='^')\n",
    "    plt.scatter(data_xlist[1], data_ylist[1], label='2', color='r', s=25, marker='v')\n",
    "    plt.scatter(data_xlist[2], data_ylist[2], label='3', color='b', s=25, marker='*')\n",
    "    plt.scatter(cent_xlist, cent_ylist, label='Cents', color='k', s=80, marker='X')\n",
    "\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title('BiKmeans')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
